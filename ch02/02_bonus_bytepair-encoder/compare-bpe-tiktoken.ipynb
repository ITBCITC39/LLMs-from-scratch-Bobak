{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c503e5ef-6bb4-45c3-ac49-0e016cedd8d0",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9e554f-58e3-4787-832d-d149add1b857",
   "metadata": {},
   "source": [
    "- Install the additional package requirements for this bonus notebook by uncommenting and running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "id": "d70bae22-b540-4a13-ab01-e748cb9d55c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:10.545359Z",
     "start_time": "2025-03-13T15:57:10.542531Z"
    }
   },
   "source": [
    "# pip install -r requirements-extra.txt"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "737c59bb-5922-46fc-a787-1369d70925b4",
   "metadata": {},
   "source": [
    "# Comparing Various Byte Pair Encoding (BPE) Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9adc3bf-353c-411e-a471-0e92786e7103",
   "metadata": {},
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## Using BPE from `tiktoken`"
   ]
  },
  {
   "cell_type": "code",
   "id": "1c490fca-a48a-47fa-a299-322d1a08ad17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:06.702125Z",
     "start_time": "2025-03-13T15:57:06.691701Z"
    }
   },
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "0952667c-ce84-4f21-87db-59f52b44cec4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:05.106568Z",
     "start_time": "2025-03-13T15:57:05.102862Z"
    }
   },
   "source": [
    "import tiktoken\n",
    "\n",
    "tik_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"Hello, world. Is this-- a test?\""
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "b039c350-18ad-48fb-8e6a-085702dfc330",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:02.432710Z",
     "start_time": "2025-03-13T15:57:02.419821Z"
    }
   },
   "source": [
    "integers = tik_tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 995, 13, 1148, 428, 438, 257, 1332, 30]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "7b152ba4-04d3-41cc-849f-adedcfb8cabb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:56:59.181018Z",
     "start_time": "2025-03-13T15:56:59.176917Z"
    }
   },
   "source": [
    "strings = tik_tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world. Is this-- a test?\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "cf148a1a-316b-43ec-b7ba-1b6d409ce837",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:56:58.040437Z",
     "start_time": "2025-03-13T15:56:58.034524Z"
    }
   },
   "source": [
    "print(tik_tokenizer.n_vocab)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "6a0b5d4f-2af9-40de-828c-063c4243e771",
   "metadata": {},
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## Using the original BPE implementation used in GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "id": "0903108c-65cb-4ae1-967a-2155e25349c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:56:56.395808Z",
     "start_time": "2025-03-13T15:56:56.392711Z"
    }
   },
   "source": [
    "from bpe_openai_gpt2 import get_encoder, download_vocab"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "35dd8d7c-8c12-4b68-941a-0fd05882dd45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:56:53.855395Z",
     "start_time": "2025-03-13T15:56:52.911896Z"
    }
   },
   "source": [
    "download_vocab()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching encoder.json: 1.04Mit [00:00, 3.80Mit/s]                                                   \n",
      "Fetching vocab.bpe: 457kit [00:00, 2.07Mit/s]                                                       \n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "1888a7a9-9c40-4fe0-99b4-ebd20aa1ffd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:56:51.081437Z",
     "start_time": "2025-03-13T15:56:51.030689Z"
    }
   },
   "source": [
    "orig_tokenizer = get_encoder(model_name=\"gpt2_model\", models_dir=\".\")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "2740510c-a78a-4fba-ae18-2b156ba2dfef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:56:49.409144Z",
     "start_time": "2025-03-13T15:56:49.405706Z"
    }
   },
   "source": [
    "integers = orig_tokenizer.encode(text)\n",
    "\n",
    "print(integers)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 995, 13, 1148, 428, 438, 257, 1332, 30]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "434d115e-990d-42ad-88dd-31323a96e10f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:56:47.899052Z",
     "start_time": "2025-03-13T15:56:47.895328Z"
    }
   },
   "source": [
    "strings = orig_tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world. Is this-- a test?\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "4f63e8c6-707c-4d66-bcf8-dd790647cc86",
   "metadata": {},
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## Using the BPE via Hugging Face transformers"
   ]
  },
  {
   "cell_type": "code",
   "id": "e9077bf4-f91f-42ad-ab76-f3d89128510e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T18:56:39.079853Z",
     "start_time": "2025-03-14T18:56:38.849633Z"
    }
   },
   "source": [
    "import transformers\n",
    "\n",
    "transformers.__version__"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[54]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\n\u001B[32m      3\u001B[39m transformers.__version__\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'transformers'"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "id": "a9839137-b8ea-4a2c-85fc-9a63064cf8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:19.912769Z",
     "start_time": "2025-03-13T15:57:19.882678Z"
    }
   },
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "hf_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[34]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m GPT2Tokenizer\n\u001B[32m      3\u001B[39m hf_tokenizer = GPT2Tokenizer.from_pretrained(\u001B[33m\"\u001B[39m\u001B[33mgpt2\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'transformers'"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "222cbd69-6a3d-4868-9c1f-421ffc9d5fe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:21.820406Z",
     "start_time": "2025-03-13T15:57:21.799499Z"
    }
   },
   "source": [
    "hf_tokenizer(strings)[\"input_ids\"]"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[35]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mhf_tokenizer\u001B[49m(strings)[\u001B[33m\"\u001B[39m\u001B[33minput_ids\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[31mNameError\u001B[39m: name 'hf_tokenizer' is not defined"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "a6233552",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:23.211792Z",
     "start_time": "2025-03-13T15:57:23.192600Z"
    }
   },
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "hf_tokenizer_fast = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[36]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m GPT2TokenizerFast\n\u001B[32m      3\u001B[39m hf_tokenizer_fast = GPT2TokenizerFast.from_pretrained(\u001B[33m\"\u001B[39m\u001B[33mgpt2\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'transformers'"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "fa5ca643",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:25.051339Z",
     "start_time": "2025-03-13T15:57:25.020973Z"
    }
   },
   "source": [
    "hf_tokenizer_fast(strings)[\"input_ids\"]"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_tokenizer_fast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[37]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mhf_tokenizer_fast\u001B[49m(strings)[\u001B[33m\"\u001B[39m\u001B[33minput_ids\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[31mNameError\u001B[39m: name 'hf_tokenizer_fast' is not defined"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "9d0f2e95-8ae8-4606-a8e0-b0fce91cfac9",
   "metadata": {},
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## Using my own from-scratch BPE tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "b6e6b1a5-9dc0-4b20-9a8b-c02aa0e3191c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:27.461483Z",
     "start_time": "2025-03-13T15:57:27.285576Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import io\n",
    "import nbformat\n",
    "import types\n",
    "\n",
    "def import_from_notebook():\n",
    "    def import_definitions_from_notebook(fullname, names):\n",
    "        current_dir = os.getcwd()\n",
    "        path = os.path.join(current_dir, \"..\", \"05_bpe-from-scratch\", fullname + \".ipynb\")\n",
    "        path = os.path.normpath(path)\n",
    "\n",
    "        # Load the notebook\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Notebook file not found at: {path}\")\n",
    "\n",
    "        with io.open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "        # Create a module to store the imported functions and classes\n",
    "        mod = types.ModuleType(fullname)\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # Go through the notebook cells and only execute function or class definitions\n",
    "        for cell in nb.cells:\n",
    "            if cell.cell_type == \"code\":\n",
    "                cell_code = cell.source\n",
    "                for name in names:\n",
    "                    # Check for function or class definitions\n",
    "                    if f\"def {name}\" in cell_code or f\"class {name}\" in cell_code:\n",
    "                        exec(cell_code, mod.__dict__)\n",
    "        return mod\n",
    "\n",
    "    fullname = \"bpe-from-scratch\"\n",
    "    names = [\"BPETokenizerSimple\"]\n",
    "\n",
    "    return import_definitions_from_notebook(fullname, names)"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "04fbd764-ec98-44f1-9b0a-e9db9a3bb91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:29.715804Z",
     "start_time": "2025-03-13T15:57:29.607310Z"
    }
   },
   "source": [
    "imported_module = import_from_notebook()\n",
    "BPETokenizerSimple = getattr(imported_module, \"BPETokenizerSimple\", None)\n",
    "\n",
    "tokenizer_gpt2 = BPETokenizerSimple()\n",
    "tokenizer_gpt2.load_vocab_and_merges_from_openai(\n",
    "    vocab_path=os.path.join(\"gpt2_model\", \"encoder.json\"),\n",
    "    bpe_merges_path=os.path.join(\"gpt2_model\", \"vocab.bpe\")\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "5a5def88-1d2c-4550-a5e8-ee82b72b92d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:31.404459Z",
     "start_time": "2025-03-13T15:57:31.383240Z"
    }
   },
   "source": [
    "integers = tokenizer_gpt2.encode(text)\n",
    "\n",
    "print(integers)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 995, 13, 1148, 428, 438, 257, 1332, 30]\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "907a1ade-3401-4f2e-9017-7f58a60cbd98",
   "metadata": {},
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## A quick performance benchmark"
   ]
  },
  {
   "cell_type": "code",
   "id": "a61bb445-b151-4a2f-8180-d4004c503754",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:34.392773Z",
     "start_time": "2025-03-13T15:57:34.384934Z"
    }
   },
   "source": [
    "with open(\"../01_main-chapter-code/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "9c0ae9f0-47a1-4e7f-a210-e1d2721f4d1e",
   "metadata": {},
   "source": [
    "### Original OpenAI GPT-2 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "57f7c0a3-c1fd-4313-af34-68e78eb33653",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:58:58.822782Z",
     "start_time": "2025-03-13T15:58:52.292168Z"
    }
   },
   "source": [
    "%timeit orig_tokenizer.encode(raw_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.97 ms ± 318 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "id": "ef2ce3f3-1f81-47ce-b563-99fe2c7a1e90",
   "metadata": {},
   "source": [
    "### Tiktoken OpenAI GPT-2 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "036dd628-3591-46c9-a5ce-b20b105a8062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:58:52.279146Z",
     "start_time": "2025-03-13T15:58:33.229292Z"
    }
   },
   "source": [
    "%timeit tik_tokenizer.encode(raw_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.35 ms ± 999 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "id": "0c748de8-273e-42df-b078-3a510106da60",
   "metadata": {},
   "source": [
    "### Hugging Face OpenAI GPT-2 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "b9c85b58-bfbc-465e-9a7e-477e53d55c90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:58:30.528327Z",
     "start_time": "2025-03-13T15:58:30.446509Z"
    }
   },
   "source": [
    "%timeit hf_tokenizer(raw_text)[\"input_ids\"]"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[51]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtimeit\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mhf_tokenizer(raw_text)[\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43minput_ids\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m]\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2481\u001B[39m, in \u001B[36mInteractiveShell.run_line_magic\u001B[39m\u001B[34m(self, magic_name, line, _stack_depth)\u001B[39m\n\u001B[32m   2479\u001B[39m     kwargs[\u001B[33m'\u001B[39m\u001B[33mlocal_ns\u001B[39m\u001B[33m'\u001B[39m] = \u001B[38;5;28mself\u001B[39m.get_local_scope(stack_depth)\n\u001B[32m   2480\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.builtin_trap:\n\u001B[32m-> \u001B[39m\u001B[32m2481\u001B[39m     result = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2483\u001B[39m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[32m   2484\u001B[39m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[32m   2485\u001B[39m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[32m   2486\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:1221\u001B[39m, in \u001B[36mExecutionMagics.timeit\u001B[39m\u001B[34m(self, line, cell, local_ns)\u001B[39m\n\u001B[32m   1219\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m0\u001B[39m, \u001B[32m10\u001B[39m):\n\u001B[32m   1220\u001B[39m     number = \u001B[32m10\u001B[39m ** index\n\u001B[32m-> \u001B[39m\u001B[32m1221\u001B[39m     time_number = \u001B[43mtimer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1222\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m time_number >= \u001B[32m0.2\u001B[39m:\n\u001B[32m   1223\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:182\u001B[39m, in \u001B[36mTimer.timeit\u001B[39m\u001B[34m(self, number)\u001B[39m\n\u001B[32m    180\u001B[39m gc.disable()\n\u001B[32m    181\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m     timing = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtimer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    183\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    184\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m gcold:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<magic-timeit>:1\u001B[39m, in \u001B[36minner\u001B[39m\u001B[34m(_it, _timer)\u001B[39m\n",
      "\u001B[31mNameError\u001B[39m: name 'hf_tokenizer' is not defined"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "7117107f-22a6-46b4-a442-712d50b3ac7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:58:26.212579Z",
     "start_time": "2025-03-13T15:58:26.128760Z"
    }
   },
   "source": [
    "%timeit hf_tokenizer(raw_text, max_length=5145, truncation=True)[\"input_ids\"]"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[49]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtimeit\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mhf_tokenizer(raw_text, max_length=5145, truncation=True)[\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43minput_ids\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m]\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2481\u001B[39m, in \u001B[36mInteractiveShell.run_line_magic\u001B[39m\u001B[34m(self, magic_name, line, _stack_depth)\u001B[39m\n\u001B[32m   2479\u001B[39m     kwargs[\u001B[33m'\u001B[39m\u001B[33mlocal_ns\u001B[39m\u001B[33m'\u001B[39m] = \u001B[38;5;28mself\u001B[39m.get_local_scope(stack_depth)\n\u001B[32m   2480\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.builtin_trap:\n\u001B[32m-> \u001B[39m\u001B[32m2481\u001B[39m     result = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2483\u001B[39m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[32m   2484\u001B[39m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[32m   2485\u001B[39m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[32m   2486\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:1221\u001B[39m, in \u001B[36mExecutionMagics.timeit\u001B[39m\u001B[34m(self, line, cell, local_ns)\u001B[39m\n\u001B[32m   1219\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m0\u001B[39m, \u001B[32m10\u001B[39m):\n\u001B[32m   1220\u001B[39m     number = \u001B[32m10\u001B[39m ** index\n\u001B[32m-> \u001B[39m\u001B[32m1221\u001B[39m     time_number = \u001B[43mtimer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1222\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m time_number >= \u001B[32m0.2\u001B[39m:\n\u001B[32m   1223\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:182\u001B[39m, in \u001B[36mTimer.timeit\u001B[39m\u001B[34m(self, number)\u001B[39m\n\u001B[32m    180\u001B[39m gc.disable()\n\u001B[32m    181\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m     timing = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtimer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    183\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    184\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m gcold:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<magic-timeit>:1\u001B[39m, in \u001B[36minner\u001B[39m\u001B[34m(_it, _timer)\u001B[39m\n",
      "\u001B[31mNameError\u001B[39m: name 'hf_tokenizer' is not defined"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "d6bfc7f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:58:27.422539Z",
     "start_time": "2025-03-13T15:58:27.362517Z"
    }
   },
   "source": [
    "%timeit hf_tokenizer_fast(raw_text)[\"input_ids\"]"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_tokenizer_fast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[50]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtimeit\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mhf_tokenizer_fast(raw_text)[\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43minput_ids\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m]\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2481\u001B[39m, in \u001B[36mInteractiveShell.run_line_magic\u001B[39m\u001B[34m(self, magic_name, line, _stack_depth)\u001B[39m\n\u001B[32m   2479\u001B[39m     kwargs[\u001B[33m'\u001B[39m\u001B[33mlocal_ns\u001B[39m\u001B[33m'\u001B[39m] = \u001B[38;5;28mself\u001B[39m.get_local_scope(stack_depth)\n\u001B[32m   2480\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.builtin_trap:\n\u001B[32m-> \u001B[39m\u001B[32m2481\u001B[39m     result = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2483\u001B[39m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[32m   2484\u001B[39m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[32m   2485\u001B[39m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[32m   2486\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:1221\u001B[39m, in \u001B[36mExecutionMagics.timeit\u001B[39m\u001B[34m(self, line, cell, local_ns)\u001B[39m\n\u001B[32m   1219\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m0\u001B[39m, \u001B[32m10\u001B[39m):\n\u001B[32m   1220\u001B[39m     number = \u001B[32m10\u001B[39m ** index\n\u001B[32m-> \u001B[39m\u001B[32m1221\u001B[39m     time_number = \u001B[43mtimer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1222\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m time_number >= \u001B[32m0.2\u001B[39m:\n\u001B[32m   1223\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:182\u001B[39m, in \u001B[36mTimer.timeit\u001B[39m\u001B[34m(self, number)\u001B[39m\n\u001B[32m    180\u001B[39m gc.disable()\n\u001B[32m    181\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m     timing = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtimer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    183\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    184\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m gcold:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<magic-timeit>:1\u001B[39m, in \u001B[36minner\u001B[39m\u001B[34m(_it, _timer)\u001B[39m\n",
      "\u001B[31mNameError\u001B[39m: name 'hf_tokenizer_fast' is not defined"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "da57c95a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:56:35.383152Z",
     "start_time": "2025-03-13T15:56:35.324360Z"
    }
   },
   "source": [
    "%timeit hf_tokenizer_fast(raw_text, max_length=5145, truncation=True)[\"input_ids\"]"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_tokenizer_fast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtimeit\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mhf_tokenizer_fast(raw_text, max_length=5145, truncation=True)[\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43minput_ids\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m]\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2481\u001B[39m, in \u001B[36mInteractiveShell.run_line_magic\u001B[39m\u001B[34m(self, magic_name, line, _stack_depth)\u001B[39m\n\u001B[32m   2479\u001B[39m     kwargs[\u001B[33m'\u001B[39m\u001B[33mlocal_ns\u001B[39m\u001B[33m'\u001B[39m] = \u001B[38;5;28mself\u001B[39m.get_local_scope(stack_depth)\n\u001B[32m   2480\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.builtin_trap:\n\u001B[32m-> \u001B[39m\u001B[32m2481\u001B[39m     result = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2483\u001B[39m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[32m   2484\u001B[39m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[32m   2485\u001B[39m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[32m   2486\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:1221\u001B[39m, in \u001B[36mExecutionMagics.timeit\u001B[39m\u001B[34m(self, line, cell, local_ns)\u001B[39m\n\u001B[32m   1219\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m0\u001B[39m, \u001B[32m10\u001B[39m):\n\u001B[32m   1220\u001B[39m     number = \u001B[32m10\u001B[39m ** index\n\u001B[32m-> \u001B[39m\u001B[32m1221\u001B[39m     time_number = \u001B[43mtimer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1222\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m time_number >= \u001B[32m0.2\u001B[39m:\n\u001B[32m   1223\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:182\u001B[39m, in \u001B[36mTimer.timeit\u001B[39m\u001B[34m(self, number)\u001B[39m\n\u001B[32m    180\u001B[39m gc.disable()\n\u001B[32m    181\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m     timing = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtimer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    183\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    184\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m gcold:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<magic-timeit>:1\u001B[39m, in \u001B[36minner\u001B[39m\u001B[34m(_it, _timer)\u001B[39m\n",
      "\u001B[31mNameError\u001B[39m: name 'hf_tokenizer_fast' is not defined"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "91ac2876-f36e-498c-bd75-8597a39f2d4b",
   "metadata": {},
   "source": [
    "### My own GPT-2 tokenizer (for educational purposes)"
   ]
  },
  {
   "cell_type": "code",
   "id": "3b4ff4d5-f2d9-4ea6-a51c-023dbba15429",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:56:33.804954Z",
     "start_time": "2025-03-13T15:56:33.649156Z"
    }
   },
   "source": [
    "%timeit tokenizer_gpt2.encode(raw_text)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer_gpt2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtimeit\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtokenizer_gpt2.encode(raw_text)\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2481\u001B[39m, in \u001B[36mInteractiveShell.run_line_magic\u001B[39m\u001B[34m(self, magic_name, line, _stack_depth)\u001B[39m\n\u001B[32m   2479\u001B[39m     kwargs[\u001B[33m'\u001B[39m\u001B[33mlocal_ns\u001B[39m\u001B[33m'\u001B[39m] = \u001B[38;5;28mself\u001B[39m.get_local_scope(stack_depth)\n\u001B[32m   2480\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.builtin_trap:\n\u001B[32m-> \u001B[39m\u001B[32m2481\u001B[39m     result = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2483\u001B[39m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[32m   2484\u001B[39m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[32m   2485\u001B[39m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[32m   2486\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:1221\u001B[39m, in \u001B[36mExecutionMagics.timeit\u001B[39m\u001B[34m(self, line, cell, local_ns)\u001B[39m\n\u001B[32m   1219\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m0\u001B[39m, \u001B[32m10\u001B[39m):\n\u001B[32m   1220\u001B[39m     number = \u001B[32m10\u001B[39m ** index\n\u001B[32m-> \u001B[39m\u001B[32m1221\u001B[39m     time_number = \u001B[43mtimer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1222\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m time_number >= \u001B[32m0.2\u001B[39m:\n\u001B[32m   1223\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CompSci /LLMs-from-scratch-Bobak/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:182\u001B[39m, in \u001B[36mTimer.timeit\u001B[39m\u001B[34m(self, number)\u001B[39m\n\u001B[32m    180\u001B[39m gc.disable()\n\u001B[32m    181\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m     timing = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtimer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    183\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    184\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m gcold:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<magic-timeit>:1\u001B[39m, in \u001B[36minner\u001B[39m\u001B[34m(_it, _timer)\u001B[39m\n",
      "\u001B[31mNameError\u001B[39m: name 'tokenizer_gpt2' is not defined"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
